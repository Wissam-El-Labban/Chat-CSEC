{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain, ConversationChain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "import keys\n",
    "\n",
    "OPENAI_API_KEY = keys.OPENAI_API_KEY\n",
    "PINECONE_API_KEY = keys.PINECONE_API_KEY\n",
    "PINECONE_API_ENV = keys.PINECONE_API_ENV\n",
    "\n",
    "#there are many options from the above that can be used. Langchain offeres many libraries that allow users to interact with OpenAIs LLMS given that they have an API key \n",
    "#for this code however, the lines from embeddings, chat_models, memory, and qa chain are used\n",
    "# embeddings are used to convert the textual infroamtion in documents into vector data that the LLM can understand and query using the semantics in a users query to find relevant results\n",
    "# ChatOpenAI gives us the ability to choose which LLM we can use. The LLM will look into the vector databse and contruct an answer. We will use our fine tuned instance once we find a way to make it accessible throught this code\n",
    "# ChatMessage History allows use to build a history object where the LLM keeps track of user questions and AI responses to keep the conversation relevant\n",
    "# load_qa_chain is the question an answer chain that allows us to run the a user quer with the vector database. usually this function returns a generic response. but the code below has an input documents similarity parameter to get relevant information\n",
    "\n",
    "\n",
    "\n",
    "# always remove the API key before committing code to github. \n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# temperature in the function below is 0. this is the randomness variable. a temperature value > 1 will be completely random. \n",
    "# the value below is at 0 to have no randomness. this coupled with our relevant document search is our method of mitigating hallucinations from the LLM\n",
    "\n",
    "#llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0, openai_api_key=API_Key)\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of retrieved documents to answer the question at the end. Please think rationally, take chat history into consideration, and answer from your own knowledge base. If you really can't construct an answer, then answer with 'no'.\n",
    "{context}\n",
    "{chat_history}\n",
    "question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\", \"chat_history\"])\n",
    "chain_type_kywargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "model_name = 'gpt-3.5-turbo'\n",
    "#llm = ChatOpenAI(model=model_name,temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "#chain = load_qa_chain(llm, chain_type='stuff')\n",
    "\n",
    "# initializing history to track the conversation\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "\n",
    "# the value below only shows the messages from the entire conversation history\n",
    "history.messages\n",
    "\n",
    "query = ''\n",
    "\n",
    "global memory\n",
    "\n",
    "model = ChatOpenAI(model_name=model_name, temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our database value is vectordb. we are using the file db2 which has our pdfs and CSVs. we had db and db (csv) as test cases aginst information in pdfs and CSVs. \n",
    "# we did not know how a vector databse would behave if we gave put differently structued data in one place. but its working out well so far. \n",
    "\n",
    "vectordb = Chroma(persist_directory='db2', embedding_function=embeddings)\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=model, retriever=vectordb.as_retriever(search_type=\"similarity\", search_kwargs={'K': 10}), memory=memory, combine_docs_chain_kwargs={\"prompt\":PROMPT})\n",
    "gpt_qa = ConversationChain(llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning a retriever function to a value. this allows the program to retrieve documents for our similartiy search which matches the semantics of our query to info in the databse\n",
    "\n",
    "#from langchain.retrievers import SVMRetriever\n",
    "#retriever = vectordb.as_retriever()\n",
    "\n",
    "#svm_retriever = SVMRetriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: what is malware\n",
      "\n",
      "Chat CSEC: Malware is a general term for all types of malicious software that is used with the aim of attempting to breach a computer system's security policy with respect to confidentiality, integrity, or availability. It refers to a broad class of attacks that are loaded on a system, typically without the knowledge of the legitimate owner, to compromise the system to the benefit of an adversary. Some examples of malware include viruses, worms, Trojan horses, spyware, and bot executables. Malware can infect systems in various ways, such as propagation from infected machines, tricking users to open tainted files, or enticing users to visit malware propagating websites. It can be inserted at any point in the system life cycle and can affect a range of victims, from end user systems to servers.\n",
      "\n",
      "Human: explain it in more detail\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat CSEC: Malware, short for malicious software, is a term used to describe any type of software that is designed to harm or exploit computer systems. It encompasses a broad range of attacks and can take various forms, including viruses, worms, Trojan horses, spyware, and bot executables.\n",
      "\n",
      "Viruses are pieces of code that can attach themselves to other system programs and replicate themselves, spreading from one system to another. They can cause damage to files, slow down computer performance, and even render systems inoperable.\n",
      "\n",
      "Worms are similar to viruses but do not require a host program to spread. They can replicate themselves and spread across networks, often exploiting vulnerabilities in computer systems.\n",
      "\n",
      "Trojan horses are programs that appear harmless or useful but contain hidden malicious code. They can be used to gain unauthorized access to systems, steal sensitive information, or perform other malicious activities.\n",
      "\n",
      "Spyware is designed to secretly gather information about a user's activities and transmit it to a third party. It can track keystrokes, capture passwords, monitor browsing habits, and collect personal information without the user's knowledge or consent.\n",
      "\n",
      "Bot executables, or bots, are programs that can be remotely controlled by an attacker. They can be used to carry out various malicious activities, such as launching distributed denial-of-service (DDoS) attacks, sending spam emails, or stealing sensitive data.\n",
      "\n",
      "In addition to these types, there are also ransomware, scareware, and rootkits. Ransomware encrypts a user's files and demands a ransom for their release. Scareware tricks users into believing their systems are infected and prompts them to purchase fake antivirus software. Rootkits are designed to gain privileged access to a system and hide malicious activities from detection.\n",
      "\n",
      "Malware can infect systems through various means, including propagation from infected machines, tricking users into opening tainted files, or enticing users to visit malware propagating websites. It can be inserted at any point in the system life cycle and can affect a range of victims, from individual end user systems to large servers.\n",
      "\n",
      "The detection and prevention of malware is an ongoing challenge, as malware authors constantly develop new techniques to evade analysis and detection. The anti-malware industry works to build systems and solutions that can effectively combat malware and protect computer systems from these threats.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the below is our current chat backend. in later sprints we will have user interface. but the below is fine for our testing purposes\n",
    "# if the user types exit, the loop ends\n",
    "while True:\n",
    "    query = str(input(\"Human: \"))\n",
    "    if query == 'exit':\n",
    "        break\n",
    "    print(f'Human: {query}')\n",
    "    print()\n",
    "    response = qa.run(query)\n",
    "    \n",
    "    if response == 'no' or response == 'No' or response == 'no.' or response == 'No.':\n",
    "        print(\"referring to chatgpt\")\n",
    "        gptresponse = gpt_qa.run(query)\n",
    "        print(gptresponse)\n",
    "        memory.save_context({\"input\": query}, {\"output\": gptresponse})\n",
    "        print()\n",
    "    else:\n",
    "        print(f'Chat CSEC: {response}')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatCSEC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
